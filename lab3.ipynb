{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모두를 위한 딥러닝 Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent를 직접 구현해 보자. [ H(x) = W * x라고 가정한다.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H(x)\n",
    "hypothesis = W * X\n",
    "\n",
    "# cost(W)\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) * 2\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00081305526 [1.0131994]\n",
      "1 3.6131216e-06 [1.0008799]\n",
      "2 1.6053036e-08 [1.0000587]\n",
      "3 7.316222e-11 [1.0000039]\n",
      "4 2.6526928e-13 [1.0000002]\n",
      "5 0.0 [1.]\n",
      "6 0.0 [1.]\n",
      "7 0.0 [1.]\n",
      "8 0.0 [1.]\n",
      "9 0.0 [1.]\n",
      "10 0.0 [1.]\n",
      "11 0.0 [1.]\n",
      "12 0.0 [1.]\n",
      "13 0.0 [1.]\n",
      "14 0.0 [1.]\n",
      "15 0.0 [1.]\n",
      "16 0.0 [1.]\n",
      "17 0.0 [1.]\n",
      "18 0.0 [1.]\n",
      "19 0.0 [1.]\n",
      "20 0.0 [1.]\n"
     ]
    }
   ],
   "source": [
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={ X : x_data, Y : y_data})\n",
    "    print(step, sess.run(cost,feed_dict= { X : x_data, Y: y_data }),sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute_gradients함수를 사용하여 직접 만든 gradient와 tf의 gradient를 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "W = tf.Variable(5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = W * X\n",
    "\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost에 맞는 gradient 값을 gvs에 할당한다.\n",
    "gvs = optimizer.compute_gradients(cost,[W])\n",
    "# Apply gradient\n",
    "apply_gradients = optimizer.apply_gradients(gvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [37.333332, 5.0, [(37.333336, 5.0)]]\n",
      "1 [2.4888866, 1.2666664, [(2.4888866, 1.2666664)]]\n",
      "2 [0.1659259, 1.0177778, [(0.1659259, 1.0177778)]]\n",
      "3 [0.011061668, 1.0011852, [(0.011061668, 1.0011852)]]\n",
      "4 [0.00073742867, 1.000079, [(0.00073742867, 1.000079)]]\n",
      "5 [4.895528e-05, 1.0000052, [(4.8955284e-05, 1.0000052)]]\n",
      "6 [3.0994415e-06, 1.0000004, [(3.0994415e-06, 1.0000004)]]\n",
      "7 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "8 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "9 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "10 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "11 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "12 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "13 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "14 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "15 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "16 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "17 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "18 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "19 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "20 [0.0, 1.0, [(0.0, 1.0)]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(21):\n",
    "    print(step, sess.run([gradient, W, gvs]))\n",
    "    sess.run(apply_gradients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
