{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모두를 위한 딥러닝 Lab9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0],[0,1],[1,0],[1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0],[1],[1],[0]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y),dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1534417\n",
      "100 0.7163875\n",
      "200 0.70198506\n",
      "300 0.69670546\n",
      "400 0.6946317\n",
      "500 0.69378406\n",
      "600 0.693426\n",
      "700 0.693271\n",
      "800 0.6932026\n",
      "900 0.6931722\n",
      "1000 0.69315845\n",
      "1100 0.6931523\n",
      "1200 0.69314957\n",
      "1300 0.69314826\n",
      "1400 0.69314766\n",
      "1500 0.6931474\n",
      "1600 0.6931473\n",
      "1700 0.6931472\n",
      "1800 0.6931471\n",
      "1900 0.6931472\n",
      "2000 0.6931472\n",
      "2100 0.6931472\n",
      "2200 0.6931472\n",
      "2300 0.6931472\n",
      "2400 0.6931472\n",
      "2500 0.6931472\n",
      "2600 0.6931471\n",
      "2700 0.6931472\n",
      "2800 0.6931472\n",
      "2900 0.6931472\n",
      "3000 0.6931472\n",
      "3100 0.6931472\n",
      "3200 0.6931472\n",
      "3300 0.6931472\n",
      "3400 0.6931472\n",
      "3500 0.6931471\n",
      "3600 0.6931472\n",
      "3700 0.6931472\n",
      "3800 0.6931472\n",
      "3900 0.6931472\n",
      "4000 0.6931472\n",
      "4100 0.6931472\n",
      "4200 0.6931472\n",
      "4300 0.6931472\n",
      "4400 0.6931472\n",
      "4500 0.6931472\n",
      "4600 0.6931472\n",
      "4700 0.6931472\n",
      "4800 0.6931472\n",
      "4900 0.6931472\n",
      "5000 0.6931472\n",
      "5100 0.6931472\n",
      "5200 0.6931472\n",
      "5300 0.6931472\n",
      "5400 0.6931472\n",
      "5500 0.6931472\n",
      "5600 0.6931472\n",
      "5700 0.6931472\n",
      "5800 0.6931472\n",
      "5900 0.6931472\n",
      "6000 0.6931472\n",
      "6100 0.6931472\n",
      "6200 0.6931472\n",
      "6300 0.6931472\n",
      "6400 0.6931472\n",
      "6500 0.6931472\n",
      "6600 0.6931472\n",
      "6700 0.6931472\n",
      "6800 0.6931472\n",
      "6900 0.6931472\n",
      "7000 0.6931472\n",
      "7100 0.6931472\n",
      "7200 0.6931472\n",
      "7300 0.6931472\n",
      "7400 0.6931472\n",
      "7500 0.6931472\n",
      "7600 0.6931472\n",
      "7700 0.6931472\n",
      "7800 0.6931472\n",
      "7900 0.6931472\n",
      "8000 0.6931472\n",
      "8100 0.6931472\n",
      "8200 0.6931472\n",
      "8300 0.6931472\n",
      "8400 0.6931472\n",
      "8500 0.6931472\n",
      "8600 0.6931472\n",
      "8700 0.6931472\n",
      "8800 0.6931472\n",
      "8900 0.6931472\n",
      "9000 0.6931472\n",
      "9100 0.6931472\n",
      "9200 0.6931472\n",
      "9300 0.6931472\n",
      "9400 0.6931472\n",
      "9500 0.6931472\n",
      "9600 0.6931472\n",
      "9700 0.6931472\n",
      "9800 0.6931472\n",
      "9900 0.6931472\n",
      "10000 0.6931472\n",
      "\n",
      "hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {X:x_data, Y:y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step,sess.run(cost,feed_dict={X:x_data, Y:y_data}))\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data,Y:y_data})\n",
    "    print(\"\\nhypothesis: \", h,\"\\ncorrect: \", c,\"\\naccuracy: \",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR with Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0],[0,1],[1,0],[1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0],[1],[1],[0]], dtype = np.float32)\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([2,2]), name = 'weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name = 'bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([2,1]), name = 'weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name = 'bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1,W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "optimizer = train.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.81545997\n",
      "100 0.68433607\n",
      "200 0.6754429\n",
      "300 0.66856486\n",
      "400 0.6616979\n",
      "500 0.6540638\n",
      "600 0.64534116\n",
      "700 0.6354332\n",
      "800 0.6243783\n",
      "900 0.61228204\n",
      "1000 0.59924185\n",
      "1100 0.5852621\n",
      "1200 0.57017136\n",
      "1300 0.5535427\n",
      "1400 0.5346205\n",
      "1500 0.5122714\n",
      "1600 0.48505485\n",
      "1700 0.45165625\n",
      "1800 0.41186458\n",
      "1900 0.36753452\n",
      "2000 0.32227418\n",
      "2100 0.27976614\n",
      "2200 0.2423138\n",
      "2300 0.21061917\n",
      "2400 0.184341\n",
      "2500 0.16270134\n",
      "2600 0.14485396\n",
      "2700 0.13004443\n",
      "2800 0.11765325\n",
      "2900 0.10719084\n",
      "3000 0.09827582\n",
      "3100 0.090612054\n",
      "3200 0.08396936\n",
      "3300 0.07816704\n",
      "3400 0.0730629\n",
      "3500 0.06854348\n",
      "3600 0.064517796\n",
      "3700 0.060912266\n",
      "3800 0.05766671\n",
      "3900 0.05473157\n",
      "4000 0.05206569\n",
      "4100 0.049634915\n",
      "4200 0.04741033\n",
      "4300 0.045367494\n",
      "4400 0.043485582\n",
      "4500 0.04174684\n",
      "4600 0.040135883\n",
      "4700 0.038639534\n",
      "4800 0.03724627\n",
      "4900 0.035945985\n",
      "5000 0.034729984\n",
      "5100 0.033590443\n",
      "5200 0.032520585\n",
      "5300 0.031514242\n",
      "5400 0.030566111\n",
      "5500 0.029671421\n",
      "5600 0.028825842\n",
      "5700 0.028025493\n",
      "5800 0.027266882\n",
      "5900 0.026546948\n",
      "6000 0.025862847\n",
      "6100 0.025212007\n",
      "6200 0.024592085\n",
      "6300 0.024001006\n",
      "6400 0.023436846\n",
      "6500 0.022897817\n",
      "6600 0.022382297\n",
      "6700 0.021888813\n",
      "6800 0.021416014\n",
      "6900 0.020962603\n",
      "7000 0.020527534\n",
      "7100 0.020109598\n",
      "7200 0.019707939\n",
      "7300 0.019321546\n",
      "7400 0.018949661\n",
      "7500 0.018591383\n",
      "7600 0.018246125\n",
      "7700 0.017913125\n",
      "7800 0.017591722\n",
      "7900 0.017281402\n",
      "8000 0.016981566\n",
      "8100 0.016691718\n",
      "8200 0.01641132\n",
      "8300 0.016140029\n",
      "8400 0.015877292\n",
      "8500 0.015622832\n",
      "8600 0.015376156\n",
      "8700 0.015137004\n",
      "8800 0.0149050355\n",
      "8900 0.014679883\n",
      "9000 0.0144612985\n",
      "9100 0.014248933\n",
      "9200 0.014042643\n",
      "9300 0.01384211\n",
      "9400 0.013647086\n",
      "9500 0.01345739\n",
      "9600 0.0132727735\n",
      "9700 0.013093041\n",
      "9800 0.012918023\n",
      "9900 0.012747504\n",
      "10000 0.012581346\n",
      "\n",
      "hypothesis:  [[0.01217247]\n",
      " [0.9840603 ]\n",
      " [0.98851556]\n",
      " [0.01040471]] \n",
      "correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(optimizer, feed_dict = {X:x_data, Y:y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step,sess.run(cost,feed_dict={X : x_data, Y : y_data}))\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X : x_data, Y : y_data})\n",
    "    print(\"\\nhypothesis: \", h,\"\\ncorrect: \", c,\"\\naccuracy: \",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### logistic regression을 사용했을 때보다 accuracy가 훨씬 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wide NN(많은 output)이나 deep NN(layer여러개)을 사용하는 등 변형해보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
